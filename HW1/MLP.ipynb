{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_moons, make_circles, make_blobs\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import argparse"
      ],
      "metadata": {
        "id": "6fOTY47xYagM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. `generate_dataset` — 多種二維分類資料產生器\n",
        "\n",
        "**功能**  \n",
        "- 依照使用者指定的 `dataset_type`，動態產生常見的二維 toy data：  \n",
        "  - `moons`、`circles`、`blobs`、`linear`、`xor`\n",
        "\n",
        "**重要參數**  \n",
        "- `dataset_type`：資料集類型  \n",
        "- `n_samples`：產生的總樣本數（可指定成 tuple 分別控制各類數量）  \n",
        "- `noise`：雜訊標準差（僅對 `moons`、`circles`、`xor` 有效）  \n",
        "- `centers`：`blobs` 中群聚中心數量  \n",
        "- `factor`：`circles` 內外圈半徑比例  "
      ],
      "metadata": {
        "id": "TdwUd75BZHqv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_dataset(dataset_type='moons',\n",
        "                     n_samples=200,\n",
        "                     noise=0.2,\n",
        "                     centers=3,\n",
        "                     factor=0.5,\n",
        "                     random_state=42):\n",
        "    \"\"\"產生多種二維分類資料\"\"\"\n",
        "    if dataset_type == 'moons':\n",
        "        X, y = make_moons(n_samples=n_samples,\n",
        "                          noise=noise,\n",
        "                          random_state=random_state)\n",
        "    elif dataset_type == 'circles':\n",
        "        X, y = make_circles(n_samples=n_samples,\n",
        "                            noise=noise,\n",
        "                            factor=factor,\n",
        "                            random_state=random_state)\n",
        "    elif dataset_type == 'blobs':\n",
        "        X, y = make_blobs(n_samples=n_samples,\n",
        "                          centers=centers,\n",
        "                          random_state=random_state)\n",
        "    elif dataset_type == 'linear':\n",
        "        X, y = make_blobs(n_samples=n_samples,\n",
        "                          centers=2,\n",
        "                          cluster_std=0.5,\n",
        "                          random_state=random_state)\n",
        "    elif dataset_type == 'xor':\n",
        "        np.random.seed(random_state)\n",
        "        base = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
        "        labels = np.array([0,1,1,0])\n",
        "        X = base + noise * np.random.randn(*base.shape)\n",
        "        y = labels\n",
        "    else:\n",
        "        raise ValueError(f\"不支援的 dataset_type: {dataset_type}\")\n",
        "    return X, y"
      ],
      "metadata": {
        "id": "Q0TZpI5qYcjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. `plot_dataset` — 資料分佈視覺化\n",
        "\n",
        "**功能**  \n",
        "- 將 2D 特徵 `X` 及標籤 `y` 繪製成散佈圖，方便觀察資料分佈形狀。  \n",
        "\n",
        "**重要參數**  \n",
        "- `X` (array): 特徵矩陣，shape=(n_samples, 2)  \n",
        "- `y` (array): 標籤向量，shape=(n_samples,)  \n",
        "- `title` (str): 圖片標題  \n"
      ],
      "metadata": {
        "id": "0PyKI0IOZWT_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_dataset(X, y, title='Dataset'):\n",
        "    \"\"\"繪製原始資料分佈\"\"\"\n",
        "    plt.figure(figsize=(5,5))\n",
        "    plt.scatter(X[:,0], X[:,1], c=y, cmap='bwr',\n",
        "                edgecolors='k', s=50)\n",
        "    plt.title(title)\n",
        "    plt.xlabel('$x_1$')\n",
        "    plt.ylabel('$x_2$')\n",
        "    plt.grid(alpha=0.3)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "0ZJjO8pKYeND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3a. `train_mlp_sklearn` — 使用 Scikit-learn 訓練 MLP\n",
        "\n",
        "**功能**  \n",
        "- 利用 `sklearn.neural_network.MLPClassifier` 快速定義並訓練多層感知器 (MLP)。  \n",
        "\n",
        "**重要參數**  \n",
        "- `hidden_layers` (tuple): 隱藏層神經元數量，例如 `(10, 10)`  \n",
        "- `activation` (str): 隱藏層激活函數 (`'identity'`,`'logistic'`,`'tanh'`,`'relu'`)  \n",
        "- `solver` (str): 最佳化演算法 (`'lbfgs'`,`'sgd'`,`'adam'`)  \n",
        "- `lr` (float): 初始學習率 (`learning_rate_init`)  \n",
        "- `max_iter` (int): 最大迭代次數  \n",
        "- `verbose` (bool): 是否顯示每次迭代的 loss  \n"
      ],
      "metadata": {
        "id": "dpJjryhgZZxX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_mlp_sklearn(X_train, y_train,\n",
        "                      hidden_layers=(10,10),\n",
        "                      activation='relu',\n",
        "                      solver='adam',\n",
        "                      lr=0.01,\n",
        "                      max_iter=200,\n",
        "                      random_state=42,\n",
        "                      verbose=True):\n",
        "    \"\"\"使用 scikit-learn MLPClassifier 訓練\"\"\"\n",
        "    clf = MLPClassifier(hidden_layer_sizes=hidden_layers,\n",
        "                        activation=activation,\n",
        "                        solver=solver,\n",
        "                        learning_rate_init=lr,\n",
        "                        max_iter=max_iter,\n",
        "                        random_state=random_state,\n",
        "                        verbose=verbose)\n",
        "    clf.fit(X_train, y_train)\n",
        "    return clf"
      ],
      "metadata": {
        "id": "t4trSLfcYf3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3b. `train_mlp_numpy` — 純 NumPy 手寫 MLP\n",
        "\n",
        "**功能**  \n",
        "- 從零實作 MLP forward/backward，使用 MSE loss 及 SGD 更新，適合作為教學示範。  \n",
        "\n",
        "**重要參數**  \n",
        "- `hidden_layers` (tuple): 隱藏層神經元數量  \n",
        "- `activation` (str): 隱藏層激活函數 (`'tanh'` 或 `'relu'`)  \n",
        "- `lr` (float): 學習率  \n",
        "- `max_iter` (int): 最大訓練迭代次數  \n",
        "- `verbose` (bool): 是否印出每 N 次迭代的 loss  "
      ],
      "metadata": {
        "id": "6E9yhRSXZfZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_mlp_numpy(X_train, y_train,\n",
        "                    hidden_layers=(10,10),\n",
        "                    activation='tanh',\n",
        "                    solver='sgd',\n",
        "                    lr=0.01,\n",
        "                    max_iter=200,\n",
        "                    random_state=42,\n",
        "                    verbose=True):\n",
        "    \"\"\"\n",
        "    純 NumPy 實作的簡易 MLP（二分類，MSE loss）\n",
        "    回傳 dict: weights, biases, loss_history, predict 函式\n",
        "    \"\"\"\n",
        "    np.random.seed(random_state)\n",
        "    n_samples, n_features = X_train.shape\n",
        "    y = y_train.reshape(-1,1)\n",
        "\n",
        "    # network dimensions\n",
        "    dims = [n_features] + list(hidden_layers) + [1]\n",
        "\n",
        "    # He initialization\n",
        "    weights = [np.random.randn(dims[i], dims[i+1]) * np.sqrt(2/dims[i])\n",
        "               for i in range(len(dims)-1)]\n",
        "    biases = [np.zeros((1, dims[i+1])) for i in range(len(dims)-1)]\n",
        "\n",
        "    # activation functions\n",
        "    if activation == 'tanh':\n",
        "        act = np.tanh\n",
        "        act_grad = lambda x: 1 - np.tanh(x)**2\n",
        "    elif activation == 'relu':\n",
        "        act = lambda x: np.maximum(0, x)\n",
        "        act_grad = lambda x: (x>0).astype(float)\n",
        "    else:\n",
        "        raise ValueError(\"activation 只支援 'tanh' 或 'relu'\")\n",
        "\n",
        "    sigmoid = lambda x: 1/(1+np.exp(-x))\n",
        "    sigmoid_grad = lambda s: s*(1-s)\n",
        "\n",
        "    loss_history = []\n",
        "\n",
        "    for it in range(1, max_iter+1):\n",
        "        # forward\n",
        "        a = [X_train]\n",
        "        z_list = []\n",
        "        for W, b in zip(weights[:-1], biases[:-1]):\n",
        "            z = a[-1] @ W + b\n",
        "            z_list.append(z)\n",
        "            a.append(act(z))\n",
        "        z_out = a[-1] @ weights[-1] + biases[-1]\n",
        "        z_list.append(z_out)\n",
        "        a_out = sigmoid(z_out)\n",
        "        a.append(a_out)\n",
        "\n",
        "        # loss (MSE)\n",
        "        loss = np.mean((a_out - y)**2)\n",
        "        loss_history.append(loss)\n",
        "        if verbose and it % 20 == 0:\n",
        "            print(f\"[NumPy] Iter {it:3d}, loss = {loss:.6f}\")\n",
        "\n",
        "        # backward\n",
        "        grads_W, grads_b = [], []\n",
        "        delta = (a_out - y) * sigmoid_grad(a_out)\n",
        "        # output layer grads\n",
        "        grads_W.insert(0, a[-2].T @ delta / n_samples)\n",
        "        grads_b.insert(0, np.sum(delta, axis=0, keepdims=True) / n_samples)\n",
        "        # hidden layers\n",
        "        for l in range(len(hidden_layers)-1, -1, -1):\n",
        "            delta = delta @ weights[l+1].T * act_grad(z_list[l])\n",
        "            grads_W.insert(0, a[l].T @ delta / n_samples)\n",
        "            grads_b.insert(0, np.sum(delta, axis=0, keepdims=True) / n_samples)\n",
        "\n",
        "        # update\n",
        "        for idx in range(len(weights)):\n",
        "            weights[idx] -= lr * grads_W[idx]\n",
        "            biases[idx]  -= lr * grads_b[idx]\n",
        "\n",
        "    def predict(X):\n",
        "        h = X\n",
        "        for W, b in zip(weights[:-1], biases[:-1]):\n",
        "            h = act(h @ W + b)\n",
        "        out = sigmoid(h @ weights[-1] + biases[-1])\n",
        "        return (out>0.5).astype(int).reshape(-1)\n",
        "\n",
        "    return {\n",
        "        'weights': weights,\n",
        "        'biases': biases,\n",
        "        'loss_history': loss_history,\n",
        "        'predict': predict\n",
        "    }"
      ],
      "metadata": {
        "id": "uRhCYumoYiyp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. `plot_loss_curve` — 損失曲線繪製\n",
        "\n",
        "**功能**  \n",
        "- 自動判別 Sklearn 或 NumPy MLP，畫出每次迭代的 loss 變化。  "
      ],
      "metadata": {
        "id": "wfhcDvf-Zkf8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_loss_curve(clf):\n",
        "    \"\"\"繪製訓練損失曲線 (Sklearn or NumPy)\"\"\"\n",
        "    plt.figure(figsize=(6,4))\n",
        "    if hasattr(clf, 'loss_curve_'):\n",
        "        plt.plot(clf.loss_curve_, label='Sklearn Loss')\n",
        "    else:\n",
        "        plt.plot(clf['loss_history'], label='NumPy Loss')\n",
        "    plt.xlabel('Iteration')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training Loss Curve')\n",
        "    plt.legend()\n",
        "    plt.grid(alpha=0.3)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "FrSzo5JVYkWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. `plot_decision_boundary` — 決策邊界示意\n",
        "\n",
        "**功能**  \n",
        "- 在整體輸入空間網格上用模型 `predict` 填色，並疊加訓練/測試點。  "
      ],
      "metadata": {
        "id": "pO1AWu9rZm07"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_decision_boundary(clf, X, y, X_train, y_train, X_test, y_test):\n",
        "    \"\"\"畫出決策邊界 (僅示範 Sklearn 版)\"\"\"\n",
        "    xx, yy = np.meshgrid(\n",
        "        np.linspace(X[:,0].min()-0.5, X[:,0].max()+0.5, 300),\n",
        "        np.linspace(X[:,1].min()-0.5, X[:,1].max()+0.5, 300)\n",
        "    )\n",
        "    grid = np.c_[xx.ravel(), yy.ravel()]\n",
        "    if hasattr(clf, 'predict'):\n",
        "        Z = clf.predict(grid).reshape(xx.shape)\n",
        "    else:\n",
        "        Z = clf['predict'](grid).reshape(xx.shape)\n",
        "\n",
        "    plt.figure(figsize=(6,6))\n",
        "    plt.contourf(xx, yy, Z, alpha=0.3, cmap='bwr')\n",
        "    plt.scatter(X_train[:,0], X_train[:,1], c=y_train, cmap='bwr',\n",
        "                edgecolors='k', s=50, label='Train')\n",
        "    plt.scatter(X_test[:,0], X_test[:,1], c=y_test, cmap='cool',\n",
        "                marker='x', s=80, label='Test')\n",
        "    plt.title(\"Decision Boundary\")\n",
        "    plt.xlabel('$x_1$')\n",
        "    plt.ylabel('$x_2$')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "def evaluate_model(clf, X_train, y_train, X_test, y_test):\n",
        "    \"\"\"列印準確率\"\"\"\n",
        "    if hasattr(clf, 'score'):\n",
        "        tr = clf.score(X_train, y_train)\n",
        "        te = clf.score(X_test, y_test)\n",
        "    else:\n",
        "        y_pred_tr = clf['predict'](X_train)\n",
        "        y_pred_te = clf['predict'](X_test)\n",
        "        tr = np.mean(y_pred_tr == y_train)\n",
        "        te = np.mean(y_pred_te == y_test)\n",
        "    print(f\"Train accuracy: {tr:.3f}\")\n",
        "    print(f\"Test accuracy:  {te:.3f}\")"
      ],
      "metadata": {
        "id": "Ix_BSGp_YmMZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. `__main__` — 主程式流程\n",
        "\n",
        "1. **命令列參數解析**  \n",
        "2. **資料產生與可視化**  \n",
        "3. **資料切分 (Train/Test)**  \n",
        "4. **Sklearn MLP 訓練、繪圖、評估**  \n",
        "5. **NumPy MLP 訓練、繪圖、評估**  "
      ],
      "metadata": {
        "id": "vogRGF02ZruB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    import sys\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--dataset', type=str, default='blobs',\n",
        "                        choices=['moons','circles','blobs','linear','xor'],\n",
        "                        help='選擇資料類型')\n",
        "    parser.add_argument('--n_samples', type=int, default=200)\n",
        "    parser.add_argument('--noise', type=float, default=0.2)\n",
        "    parser.add_argument('--centers', type=int, default=3)\n",
        "    parser.add_argument('--factor', type=float, default=0.5)\n",
        "    args, _ = parser.parse_known_args()\n",
        "\n",
        "    # 1. 產生並可視化資料\n",
        "    X, y = generate_dataset(dataset_type=args.dataset,\n",
        "                            n_samples=args.n_samples,\n",
        "                            noise=args.noise,\n",
        "                            centers=args.centers,\n",
        "                            factor=args.factor)\n",
        "    plot_dataset(X, y, title=f\"data: {args.dataset}\")\n",
        "\n",
        "    # 2. 切分\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "    # 3a. 訓練 Sklearn MLP\n",
        "    print(\"=== Sklearn MLP Training ===\")\n",
        "    clf_sk = train_mlp_sklearn(X_train, y_train)\n",
        "    plot_loss_curve(clf_sk)\n",
        "    plot_decision_boundary(clf_sk, X, y, X_train, y_train, X_test, y_test)\n",
        "    evaluate_model(clf_sk, X_train, y_train, X_test, y_test)\n",
        "\n",
        "    # 3b. 訓練 NumPy MLP\n",
        "    print(\"\\n=== NumPy MLP Training ===\")\n",
        "    clf_np = train_mlp_numpy(X_train, y_train,\n",
        "                             hidden_layers=(10,10),\n",
        "                             activation='tanh',\n",
        "                             lr=0.05,\n",
        "                             max_iter=200,\n",
        "                             verbose=True)\n",
        "    plot_loss_curve(clf_np)\n",
        "    evaluate_model(clf_np, X_train, y_train, X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "id": "JHTXP8DPYorG",
        "outputId": "2cc35993-a753-4fd5-cf42-ad372bd37b77"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'argparse' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3047484109.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mArgumentParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     parser.add_argument('--dataset', type=str, default='blobs',\n\u001b[1;32m      5\u001b[0m                         \u001b[0mchoices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'moons'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'circles'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'blobs'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'xor'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'argparse' is not defined"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}